# Установка библиотек
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
import numpy as np
import pandas as pd
import statsmodels.formula.api as smf
import statsmodels.api as sm
from statsmodels.tools import add_constant
from statsmodels.iolib.summary2 import summary_col, summary_params

#Чтение файла
df = pd.read_csv('Bank_Personal_Loan_Modelling.csv.xls')
df

#Многофакторный хи-квадрат

# [df['Age'], df['Experience'], df['Income'], 
#df['Family'], df['CCAvg'], df['Education'], 
#df['Mortgage'], df['Personal_Loan'], 
#df['Securities_Account'], 
#df['CD_Account'] - Есть статистически значимые различия (только у него)
#df['Online'], 
#df['CreditCard']])

import pandas as pd
from scipy.stats import chi2_contingency

contingency_table = pd.crosstab(df['CD_Account'], df['CreditCard'])

chi2, p, _, _ = chi2_contingency([contingency_table])
print(f"p-value: {p}")
if p <= 0.05:
    print("Есть статистически значимые различия.")
else:
    print("Нет статистически значимых различий.")

#Строим модель 1
mod = smf.logit(formula='CreditCard~Age+Experience+Income+Family+CCAvg+Education+Mortgage+Personal_Loan+Securities_Account+CD_Account+Online', data=df)
res = mod.fit(cov_type='HC3')
print(res.summary())

# Logit Regression Results                           
#==============================================================================
#Dep. Variable:             CreditCard   No. Observations:                 5000
 #Model:                          Logit   Df Residuals:                     4988
 #Method:                           MLE   Df Model:                           11
 #Date:                Mon, 23 Dec 2024   Pseudo R-squ.:                 0.08430
 #Time:                        23:50:55   Log-Likelihood:                -2773.2
 #converged:                       True   LL-Null:                       -3028.5
 #Covariance Type:                  HC3   LLR p-value:                1.763e-102
 #======================================================================================
 #                        coef    std err          z      P>|z|      [0.025      0.975]
 #--------------------------------------------------------------------------------------
 #Intercept             -0.6072      0.694     -0.875      0.382      -1.968       0.754
 #Age                   -0.0051      0.027     -0.186      0.852      -0.059       0.049
 #Experience             0.0062      0.027      0.225      0.822      -0.047       0.060
 #Income                 0.0002      0.001      0.206      0.837      -0.002       0.002
 #Family                 0.0323      0.029      1.102      0.270      -0.025       0.090
 #CCAvg                 -0.0235      0.025     -0.926      0.355      -0.073       0.026
 #Education             -0.0221      0.043     -0.516      0.606      -0.106       0.062
 #Mortgage              -0.0007      0.000     -1.964      0.050      -0.001   -1.21e-06
 #Personal_Loan         -1.0410      0.173     -6.013      0.000      -1.380      -0.702
 #Securities_Account    -1.3057      0.155     -8.426      0.000      -1.609      -1.002
 #CD_Account             3.6742      0.177     20.762      0.000       3.327       4.021
 #Online                -0.2864      0.067     -4.301      0.000      -0.417      -0.156
 #======================================================================================
# В модели значимы только Mortgage, Personal_Loan, Securities_Account, CD_Account, Online (p-value<=0.05)
# значит отдельно от других факторов действительно важен CD_Account (по многофакторному хи-квадрат), 
# НО ПО ФАКТУ ВАЖНЫ ВСЕ УПОМЯНУТЫЕ, ТАК КАК ВЛИЯНИЕ ИДЕТ В СВЯЗКЕ

# исправляем модель
mod_remake = smf.logit(formula='CreditCard~Mortgage+Personal_Loan+Securities_Account+CD_Account+Online', data=df1)
res_remake = mod_remake.fit(cov_type='HC3')
print(res_remake.summary())

new_data = pd.DataFrame({'Mortgage':[70, 40, 100], 
                         'Personal_Loan':[0, 1, 0], 
                         'Securities_Account': [1, 0, 0], 
                         'CD_Account': [0, 1, 1],
                         'Online': [0, 1, 0]})
res_remake.predict(exog=new_data, transform=True).round(3)

# значима ли регрессия
# Тестовая статистика LR-теста и её P-значение с округленим
llr = res_remake.llr.round(3), res.llr_pvalue.round(3)
sign_level = 0.05 # уровень значимости
chi = chi2.ppf(q=1-sign_level, df=res.df_model).round(3) 
if llr[0]>chi:
    print("Регрессия значима")
else:
    print("Регрессия не значима")

from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant

# Загружаем данные
X = df[['Mortgage', 'Personal_Loan', 'Securities_Account', 'CD_Account', 'Online']]

# Добавляем столбец константы для модели
X = add_constant(X)

# Рассчитываем VIF для каждого признака
vif_data = pd.DataFrame()
vif_data["feature"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

# Выводим результат
print(vif_data)
# VIF < 5 для всех факторов - значит мультиколлинеарности нет(избыточности факторов)



from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# Разделяем данные на обучающую и тестовую выборки
X = df[['Mortgage', 'Personal_Loan', 'Securities_Account', 'CD_Account', 'Online']]
y = df['CreditCard']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Строим логистическую регрессию
model = LogisticRegression()
model.fit(X_train, y_train)

# Прогнозируем на тестовых данных
y_pred = model.predict(X_test)
y_pred_prob = model.predict_proba(X_test)[:, 1]

# Оценка метрик
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')
print('Classification Report:')
print(classification_report(y_test, y_pred))

# ROC-AUC
roc_auc = roc_auc_score(y_test, y_pred_prob)
print(f'ROC-AUC: {roc_auc}')

# Построение ROC-кривой
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--', label='Random Classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

#ROC-кривая модели всегда находится выше 
# линии random classifier - это хорошо 
#(означает, что модель выше случайного уровня и, следовательно, 
#имеет предсказательную силу
# Accuracy: 0.752
# ROC-AUC: 0.5951600108350746

# Cравнивание модели со всеми признаками и моей модели с нужными признаками


# Полная модель (с всеми признаками)
X_full = df[['Mortgage', 'Personal_Loan', 'Securities_Account', 'CD_Account', 'Online', 'Experience', 'Income', 'Family', 'Education']]  # Все признаки
X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, y, test_size=0.2, random_state=42)

model_full = LogisticRegression()
model_full.fit(X_train_full, y_train_full)
y_pred_full = model_full.predict(X_test_full)

# Метрики для полной модели
accuracy_full = accuracy_score(y_test_full, y_pred_full)
roc_auc_full = roc_auc_score(y_test_full, model_full.predict_proba(X_test_full)[:, 1])

print(f'Full Model Accuracy: {accuracy_full}')
print(f'Full Model ROC-AUC: {roc_auc_full}')

#Full Model Accuracy: 0.752
#Full Model ROC-AUC: 0.6016223589505456
#Accuracy of my model: 0.752
#ROC-AUC of my model: 0.5951600108350746 - существенных различий нет

marge_res = res_remake.get_margeff(at='mean')

marge_res.summary()


